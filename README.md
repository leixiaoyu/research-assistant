# ARISP - Automated Research Ingestion & Synthesis Pipeline

> Automate the discovery, extraction, and synthesis of cutting-edge AI research papers with intelligent LLM-powered analysis.

[![Python 3.10.19](https://img.shields.io/badge/python-3.10.19-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Security: High](https://img.shields.io/badge/security-high-green.svg)](docs/security/)
[![Test Coverage: 98%](https://img.shields.io/badge/coverage-98%25-brightgreen.svg)](tests/)

## ğŸ¯ Overview

ARISP automates the research process by:
- ğŸ” **Discovering** papers from multiple sources (ArXiv, Semantic Scholar)
- ğŸ“„ **Processing** PDFs with concurrent multi-backend extraction
- ğŸ¤– **Extracting** prompts, code, and insights using LLM (Claude/Gemini)
- ğŸ“ **Synthesizing** Obsidian-ready markdown briefs for engineering teams
- âš¡ **Accelerating** with intelligent concurrency and resource management

**âœ¨ Phase 3.1 Complete:** Concurrent orchestration with async worker pools, semaphore-based resource limiting, and intelligent backpressure handling - 98% test coverage, 408 tests!

## âœ¨ Key Features

### Discovery (Phase 1 + 1.5)
- **Multi-Provider Support**: ArXiv (default, no API key) + Semantic Scholar (optional)
- **Configurable Topics**: User-editable YAML configuration for research queries
- **Flexible Timeframes**: Recent (48h), since year (2020+), or custom date ranges
- **Intelligent Cataloging**: Automatic deduplication and topic organization
- **100% PDF Access**: ArXiv guarantees open access PDFs for all papers

### Extraction (Phase 2 + 2.5) âœ… Complete
- **LLM-Powered Analysis**: Claude 3.5 Sonnet or Gemini 3 Flash Preview
- **Configurable Targets**: Extract prompts, code, metrics, summaries per topic
- **Cost Controls**: Budget limits, usage tracking, smart filtering
- **Multi-Backend PDF Processing**: PyMuPDF (fast) â†’ PDFPlumber (tables) â†’ Pandoc (fallback)
- **Quality-Based Selection**: Automatic backend selection using heuristic scoring
- **Reliability-First**: 100% test coverage on all extractors, production-hardened
- **Enhanced Output**: Token/cost tracking, confidence scores, extraction summaries

### Intelligence (Phase 3 + 3.1) âœ… Complete
- **Multi-Level Caching**: API responses, PDFs, extractions with 99% hit rates
- **Smart Deduplication**: Two-stage (DOI + fuzzy title) matching with 90%+ accuracy
- **Quality Filtering**: Weighted ranking (citations + recency + relevance)
- **Checkpoint/Resume**: Atomic saves for crash-safe pipeline resumption
- **Concurrent Orchestration**: Async worker pools with semaphore-based resource limiting
- **Intelligent Backpressure**: Dynamic queue management and graceful degradation
- **100% Service Coverage**: All Phase 3 services at 100% test coverage

### Production (Phase 4)
- **Observable**: Structured logging, Prometheus metrics, Grafana dashboards
- **Resilient**: Retry logic, circuit breakers, checkpoint/resume
- **Secure**: Security-first design, secrets scanning, input validation

## ğŸš€ Quick Start

### Prerequisites

**Required:**
- Python 3.10+
- LLM API key (Anthropic or Google) - for Phase 2 extraction

**Optional:**
- Semantic Scholar API key - only if you want to use Semantic Scholar instead of ArXiv

### Installation

```bash
# Clone repository
git clone https://github.com/leixiaoyu/research-assistant.git
cd research-assistant

# Create virtual environment (requires Python 3.10+)
python3.10 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.template .env
# Edit .env and add your LLM API key
# Semantic Scholar API key is optional (defaults to ArXiv)
```

### Development & Verification

Every push must pass the "Golden Path" verification:

```bash
# Run all quality checks (Formatting, Linting, Types, Tests, Coverage)
./verify.sh
```

### Configuration

**Minimal Configuration (ArXiv - No API Key Required):**

```yaml
# config/research_config.yaml
research_topics:
  - query: "attention mechanism transformers"
    timeframe:
      type: "recent"
      value: "7d"
    max_papers: 20

settings:
  output_base_dir: "./output"
  # No API key needed for ArXiv!
```

**Full Configuration (with Semantic Scholar and Extraction):**

```yaml
# config/research_config.yaml
research_topics:
  - query: "Tree of Thoughts AND machine translation"
    provider: "arxiv"  # or "semantic_scholar" (optional, defaults to arxiv)
    timeframe:
      type: "recent"
      value: "48h"
    max_papers: 50
    extraction_targets:
      - name: "system_prompts"
        description: "Extract LLM system prompts used in the paper"
        output_format: "list"
        required: false
      - name: "code_snippets"
        description: "Extract Python code implementing the methodology"
        output_format: "code"
        required: false
      - name: "engineering_summary"
        description: "Write a 2-paragraph summary for engineering teams"
        output_format: "text"
        required: true

  - query: "reinforcement learning robotics"
    provider: "semantic_scholar"  # Requires API key
    timeframe:
      type: "since_year"
      value: 2023
    max_papers: 30

settings:
  output_base_dir: "./output"
  enable_duplicate_detection: true

  # Optional: Only needed for Semantic Scholar
  semantic_scholar_api_key: "${SEMANTIC_SCHOLAR_API_KEY}"

  # Required for Phase 2 (LLM extraction)
  llm_settings:
    provider: "anthropic"  # or "google"
    model: "claude-3-5-sonnet-20250122"
    api_key: "${LLM_API_KEY}"
    max_tokens: 100000

  cost_limits:
    max_daily_spend_usd: 50.0
    max_total_spend_usd: 500.0

  # Phase 3.1: Concurrency settings (optional)
  concurrency:
    max_concurrent_papers: 3        # Parallel paper processing
    max_concurrent_downloads: 2     # Parallel PDF downloads
    max_concurrent_extractions: 2   # Parallel LLM extractions
```

### Usage

```bash
# Run pipeline (Phase 1: Discovery only)
python -m src.cli run

# Run with custom config
python -m src.cli run --config custom_research.yaml

# Validate configuration
python -m src.cli validate config/research_config.yaml

# View catalog
python -m src.cli catalog show
```

**Example Output Structure:**
```
output/
â”œâ”€â”€ catalog.json                    # Master index
â”œâ”€â”€ attention-mechanism-transformers/
â”‚   â”œâ”€â”€ 2026-01-23_Research.md    # ArXiv papers
â”‚   â””â”€â”€ papers/                    # Downloaded PDFs
â””â”€â”€ tree-of-thoughts-translation/
    â”œâ”€â”€ 2026-01-23_Research.md
    â””â”€â”€ papers/
```

## ğŸ“š Documentation

### Architecture
- **[System Architecture](docs/SYSTEM_ARCHITECTURE.md)** - Complete architecture design â­ **PRIMARY REFERENCE**
- [Architecture Review](docs/ARCHITECTURE_REVIEW.md) - Gap analysis and architectural assessment
- [Phased Delivery Plan](docs/PHASED_DELIVERY_PLAN.md) - 5-phase, ~6-week implementation roadmap

### Phase Specifications
- [Phase 1: Foundation](docs/specs/PHASE_1_SPEC.md) - âœ… Complete (Discovery, Catalog, Config)
- [Phase 1.5: Provider Abstraction](docs/specs/PHASE_1_5_SPEC.md) - âœ… Complete (ArXiv Integration)
- [Phase 2: Extraction](docs/specs/PHASE_2_SPEC.md) - âœ… Complete (PDF & LLM Extraction)
- [Phase 2.5: PDF Reliability](docs/specs/PHASE_2.5_SPEC.md) - âœ… Complete (Multi-Backend Fallback Chain)
- [Phase 3: Intelligence Layer](docs/specs/PHASE_3_SPEC.md) - âœ… Complete (Cache, Dedup, Filters, Checkpoint)
- [Phase 3.1: Concurrent Orchestration](docs/specs/PHASE_3.1_SPEC.md) - âœ… Complete (Async Workers, Resource Limiting, Backpressure)
- [Phase 3.2: Semantic Scholar Activation](docs/specs/PHASE_3.2_SPEC.md) - ğŸ¯ Ready (Multi-Provider Intelligence)
- [Phase 4: Hardening](docs/specs/PHASE_4_SPEC.md) - ğŸ“‹ Planned (Production Readiness)

### Proposals
- [Proposal 001: Discovery Provider Strategy](docs/proposals/001_DISCOVERY_PROVIDER_STRATEGY.md) - âœ… Approved & Implemented
- [Proposal 002: PDF Extraction Reliability](docs/proposals/002_PDF_EXTRACTION_RELIABILITY.md) - âœ… Approved & Implemented

### Development
- [CLAUDE.md](CLAUDE.md) - Development guide for Claude Code integration
- [Pre-Commit Hooks](docs/operations/PRE_COMMIT_HOOKS.md) - Security and quality automation
- [Dependency Security](docs/security/DEPENDENCY_SECURITY_AUDIT.md) - Vulnerability scan results

## ğŸ—ï¸ Project Status

**Current Status:** âœ… **Phase 3.1 Complete** - Concurrent orchestration operational with async worker pools, semaphore-based resource limiting, and intelligent backpressure handling. Full intelligence layer with caching, deduplication, filtering, and checkpoint/resume.

**Next Phase:** ğŸ¯ **Phase 3.2: Semantic Scholar Activation** (3-5 days) - Multi-provider intelligence with Semantic Scholar integration, or **Phase 4: Production Hardening** (1 week) - Observability, monitoring, deployment automation.

ğŸ“Š **For detailed progress tracking, timelines, and phase-by-phase completion status, see:**
â†’ **[Phased Delivery Plan](docs/PHASED_DELIVERY_PLAN.md)** (Single Source of Truth)

## ğŸ› ï¸ Tech Stack

### Core Technologies
| Category | Technology | Purpose |
|----------|-----------|---------|
| Language | Python 3.10+ | Rich ecosystem, async support |
| Data Models | Pydantic V2 | Runtime validation, type safety |
| Discovery | **ArXiv API** (default) | **No API key required** |
| Discovery | Semantic Scholar API (optional) | Comprehensive coverage |
| PDF Processing | marker-pdf | Code-preserving conversion |
| LLM | Claude 3.5 Sonnet / Gemini 1.5 Pro | 1M+ context, high quality |
| CLI | typer | Modern, type-safe interface |
| Async | asyncio + aiohttp | High-performance I/O |

### Infrastructure
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Caching | diskcache | Fast local caching |
| Logging | structlog | Structured JSON logs |
| Metrics | Prometheus | Time-series metrics |
| Dashboards | Grafana | Visualization |
| Scheduling | APScheduler | Automated runs |
| Testing | pytest | >95% coverage |
| Security | pre-commit hooks | Secret scanning, linting |

## ğŸ“Š Performance & Quality

### Current Metrics
- âœ… **Test Coverage**: 98.12% (408 automated tests, 100% pass rate)
- âœ… **Concurrency**: Async worker pools with configurable parallelism limits
- âœ… **Security**: 22/22 requirements met across all layers
- âœ… **Quality Gates**: Automated enforcement (Flake8, Black, Mypy, Pytest)
- âœ… **Configuration Validation**: <1s
- âœ… **Catalog Operations**: <100ms
- âœ… **Memory Usage**: <100MB idle
- âœ… **LLM Cost**: ~$0.005 per paper (abstract-only mode)
- âœ… **Rate Limiting**: ArXiv-compliant (3s minimum delay)
- âœ… **Environment**: Python 3.10+ (CI/CD enforced)

## ğŸ”’ Security

**Security-First Design** - All 22 security requirements enforced across all layers:

**Core Security:**
- âœ… No hardcoded secrets (environment variables only)
- âœ… Input validation (Pydantic + security utilities)
- âœ… Path sanitization (directory traversal prevention)
- âœ… Rate limiting (exponential backoff, ArXiv compliance)
- âœ… Security logging (no secrets in logs)
- âœ… Dependency scanning (pip-audit, monthly audits)
- âœ… Pre-commit hooks (secret scanning, linting)
- âœ… Configuration validation (strict schemas)
- âœ… Error handling (graceful degradation)

**Infrastructure Security:**
- âœ… File system security (atomic writes, permissions)
- âœ… API security (HTTPS only, SSL validation)
- âœ… Provider input validation (query sanitization)
- âœ… PDF URL validation (HTTPS enforcement)
- âœ… API response validation (status codes, malformed data)
- âœ… Cache directory permissions restricted
- âœ… Checkpoint atomic writes with validation

See [Security Audit](docs/security/DEPENDENCY_SECURITY_AUDIT.md) for detailed vulnerability scan results.

## ğŸ“ Use Cases

### Research Teams
- Stay current with latest papers in your field
- Extract implementation details from papers
- Build knowledge base of research findings

### Engineering Teams
- Identify applicable techniques for production systems
- Extract code snippets and prompts from papers
- Generate technical summaries for non-researchers

### AI Practitioners
- Track developments in specific AI subfields
- Extract prompts and evaluation metrics
- Build prompt libraries from research

## ğŸ’¡ Provider Comparison

| Provider | API Key | Coverage | PDF Access | Best For |
|----------|---------|----------|------------|----------|
| **ArXiv** â­ | âŒ No | AI/CS/Physics pre-prints | âœ… 100% | Cutting-edge AI research |
| **Semantic Scholar** | âœ… Yes (pending) | 200M+ papers, all fields | âš ï¸ Varies | Comprehensive research |
| **OpenAlex** (future) | Optional | 250M+ works | âš ï¸ Varies | Multi-disciplinary |
| **PubMed** (future) | âŒ No | Medical/life sciences | âš ï¸ Varies | Biomedical research |

**Recommendation:** Start with ArXiv (no setup required), add Semantic Scholar when keys arrive.

## ğŸ¤ Contributing

This project follows strict quality standards:
- âœ… Security-first development
- âœ… Test-driven development (>80% coverage)
- âœ… Complete verification before commits
- âœ… SOLID, KISS, DRY, YAGNI principles

Contributions welcome after Phase 1.5! See [CLAUDE.md](CLAUDE.md) for development guidelines.

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ“§ Contact

- **Repository**: https://github.com/leixiaoyu/research-assistant
- **Issues**: https://github.com/leixiaoyu/research-assistant/issues

## ğŸ™ Acknowledgments

- **ArXiv** for open access research papers
- **Semantic Scholar** for research paper API
- **marker-pdf** for code-preserving PDF conversion
- **Anthropic** & **Google** for LLM APIs
- **Pydantic** for data validation
- **Open source community** for excellent tooling

---

## ğŸ“– Quick Reference

### Environment Variables

```bash
# Required for Phase 2 (LLM extraction)
LLM_API_KEY=your_anthropic_or_google_api_key

# Optional (only for Semantic Scholar provider)
SEMANTIC_SCHOLAR_API_KEY=your_semantic_scholar_api_key
```

### Common Commands

```bash
# Run with ArXiv (no API key needed)
python -m src.cli run

# Run with Semantic Scholar
# (requires SEMANTIC_SCHOLAR_API_KEY in .env)
python -m src.cli run --provider semantic_scholar

# Validate config before running
python -m src.cli validate

# Check catalog of processed papers
python -m src.cli catalog show

# Run tests
pytest tests/ --cov=src --cov-report=term

# Run security checks
python -m pip_audit -r requirements.txt
pre-commit run --all-files
```

### Timeframe Examples

```yaml
# Last 48 hours
timeframe:
  type: "recent"
  value: "48h"

# Last 7 days
timeframe:
  type: "recent"
  value: "7d"

# Papers since 2023
timeframe:
  type: "since_year"
  value: 2023

# Custom date range
timeframe:
  type: "date_range"
  start_date: "2024-01-01"
  end_date: "2024-12-31"
```

---

**Built with â¤ï¸ for research teams who want to stay ahead**

**Status**: Phase 3.1 Complete - Concurrent orchestration with async worker pools, resource limiting, and intelligent backpressure. Full intelligence layer operational. 98.12% coverage, 408 tests ğŸš€
